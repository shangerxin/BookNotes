Pandas Workout=Lerner;Note=Erxin


# Dedication
• be insatiably curious

• share everything I learn

• believe in other people

• do it all with humor

# Series
- a data frame as a collection of series.

-  create a series

g = np.random.default_rng(0)
s = Series(g.integers(70, 101, 10))

- use the .loc and .iloc accessors. Whereas .loc retrieves one or more elements based on the index, 

s1 = Series([10, 20, 30, 40],
    index=list('abcd'))
s2 = Series([100, 200, 300, 400],
    index=list('dcba'))

s1+s2

- use a mask index for assignment and retrieval. For example:

s.loc[s <= s.mean()] = 999



# Data frames 
- DataFrame Returns a new data frame based on two-dimensional data

DataFrame([[10, 20], [30, 40], [50, 60]])

- s.loc  Accesses elements of a series by labels or a boolean array

s.loc['a']

- s.iloc    Accesses elements of a series by position

s.iloc[0]

- df.iloc

Accesses one or more rows of a data frame by position

df.iloc[5]

- []

Accesses one or more columns in a data frame

df['a']

- s.quantile

Gets the value at a particular percentage of the values

s.quantile(0.25)

- pd.concat

Joins together two data frames

df = pd.concat([df, new_products])

- df.query

Writes an SQL-like query

df.query('v > 300')

- pd.read_csv

Returns a new series based on a single-column file

s = pd.read_csv ('filename.csv').squeeze()

- interpolate

Returns a new data frame with NaN values interpolated

df = df.interpolate()

- df.dropna

Returns a new data frame without any NaN values

df.dropna()

- s.isin

Returns a boolean series indicating whether each element of a series is in the provided argument

s.isin([10, 20, 30])

- define dataframe 

df = DataFrame([
    [x, x, x],
    [x, x, x],
], index=list('rowtitles'), columns=list('columntitles')))


df.loc[['a', 'c']]

Graphical depiction of df.loc[['a', 'c'], ['v', 'y']]

- manipulate csv 

s = pd.read_csv('data/nyc-temps.txt').squeeze()


# Import and export data 
- pd.read_csv

Returns a new data frame based on CSV input

df = pd.read_csv('myfile.csv')

- df.to_csv

Writes a data frame to a CSV-formatted file or string

df.to_csv('myfile.csv')

- pd.read_json

Returns a new data frame based on JSON input

df = pd.read_json('myfile.json')

- df.corr

Shows the correlations among the columns

df.corr()

- df.dropna

Returns a new data frame without any NaN values

df.dropna()

- df.loc

Retrieves selected rows and columns

df.loc[df['trip_distance'] > 10, 'passenger_count']

- pd.read_html

Returns a list of data frames based on HTML input

df = df.read_html('https://a-site.com')

- s.value_counts

Returns a sorted (descending frequency) series counting how many times each value appears in s

s.value_counts()

- s.round

Returns a new series based on s in which the values are rounded to the specified number of decimals.

s.round(2)

- pd.Series.idxmin

Returns the index of the lowest value in a series

s.idxmin()
s.idxmax()

- pd.DataFrame.agg

Invokes one or more aggregation methods on a data frame

df.idxmax(['min', 'max'])


# Indexes
- pd.set_index

Returns a new data frame with a new index

df = df.set_index('name')

- pd.reset_index

Returns a new data frame with a default (numeric, positional) index

df = df.reset_index()

- df.loc

Retrieves selected rows and columns

df.loc[:, 'passenger_count'] = df['passenger_count']

- s.value_counts

Returns a sorted (descending frequency) series counting how many times each value appears in s

s.value_counts()

- s.isin

Returns a boolean series indicating whether a value in s is an element of the argument

s.isin(['A', 'B', 'C')

- df.pivot

Creates a pivot table based on a data frame without aggregation

df.pivot(index='month', columns='year', values='A')

- s.is_monotonic_increasing

Contains True if values in the series are sorted in increasing order

s.is_monotonic_increasing

- slice

Python builtin for creating slices

slice(10, 20, 2)

- slice

Python builtin for creating slices

slice(10, 20, 2)

http://mng.bz/278g

df.xs

Returns a cross-section from a data frame

df.xs(2016, level='Year')

- df.xs

Returns a cross-section from a data frame

df.xs(2016, level='Year')

- df.dropna

Returns a new data frame without any NaN values

df.dropna()

- IndexSlice

Produce an object for easier querying of data frames using xs

IndexSlice[:, 2016]

- examples 

can limit our results to the three most common makes by adding head(3) to our call
```
filename = '../data/nyc-parking-violations-2020.csv'

df = pd.read_csv(filename,
                 usecols=[
                     'Date First Observed',
                     'Registration State', 'Plate ID',
                     'Issue Date', 'Vehicle Make',
                     'Street Name', 'Vehicle Color'])
df = df.set_index('Issue Date')
df.loc['01/02/2020 12:00:00 AM', 'Vehicle Make'].value_counts().head(3)
```
set_index will make the columns as the first index column 

now we want to make queries against the Vehicle Color column. 
```
df = df.reset_index()
df = df.set_index('Vehicle Color')
```

support multiple index column 
df = df.set_index(['year', 'month'])
df.loc[(2018, 'Jun'), ['A', 'C']]

- sort data frames based on the index. We can do that with the sort_index method


```
filename = '../data/olympic_athlete_events.csv'
df = pd.read_csv(filename,
                usecols=['Age', 'Height', 'Team',
                         'Year', 'Season',
                         'Sport', 'Medal'])                  ①

df = df.loc[df['Team'].isin(['Great Britain', 'France',
                            'United States', 'Switzerland',
                            'China', 'India'])]              ②
df = df.loc[df['Year'] >= 1980]                              ③

df.pivot_table(index='Year', columns='Team',
               values='Age')                                 ④
df.pivot_table(index='Sport',
               columns='Year', values='Height',
               aggfunc='max')                                ⑤

pd.pivot_table(df.dropna(subset='Medal'),
               index='Year',
               columns='Team',
               values='Medal',
               aggfunc='size')     
```


# Cleaning data 
- df.shape

A two-element tuple indicating the number of rows and columns in a data frame

df.shape

- len(df) or len(df.index)

Gets the number of rows in a data frame

len(df) or len(df.index)

- s.isnull

Returns a boolean series indicating where there are null (typically NaN) values in the series s

s.isnull()

- s.notnull

Returns a boolean series indicating where there are non-null values in the series s

s.notnull()

- df.isnull

Returns a boolean data frame indicating where there are null (typically NaN) values in the data frame df

df.isnull()

- df.replace

Replaces values in one or more columns with other values

df.replace('a':{'b':'c'), 'd')

- s.map

Applies a function to each element of a series, returning the result of that application on each element

s.map(lambda x: x**2)

- df.fillna

Replaces NaN with other values

df.fillna(10)

- df.dropna

Removes rows with NaN values

df = df.dropna()

- s.str

Works with textual data

df['colname'].str

- str.isdigit

Returns a boolean series, indicating which strings contain only the digits 0–9

df['colname'].str.isdigit()

- pd.to_numeric

Returns a series of integers or floats based on a series of strings

pd.to_numeric(df['colname'])

- df.sort_index

Reorders the rows of a data frame based on the values in its index in ascending order

df = df.sort_index()

- pd.read_excel

Creates a data frame based on an Excel spreadsheet

df = pd.read_excel('myfile.xlsx')

- pd.read_csv

Returns a new data frame based on CSV input

df = pd.read_csv('myfile.csv')

- s.value_counts

Returns a sorted (descending frequency) series counting how many times each value appears in s

s.value_counts()

- s.unique

Returns a series with the unique (i.e., distinct) values in s, including NaN (if it occurs in s)

s.unique()

- s.mode

Returns a series with the most commonly found values in s

s.mode()

- convert type 

df['colname'] = df['colname'].astype(np.int64)

- slice 

df['dateofdeath'].str.slice(5,7)


# Grouping joining and sorting 
- s.isnull

Returns a boolean series indicating where there are null (typically NaN) values in the series s

s.isnull()

- df.sort_index

Reorder the rows of a data frame based on the values in its index, in ascending order

df = df.sort_index()

- df.sort_values

Reorder the rows of a data frame based on the values in one or more specified columns

df = df.sort_values('distance')

- df.transpose() or df.T

Returns a new data frame with the same values as df but with the columns and index exchanged

df.transpose() or df.T

- df.expanding

Lets us run window functions on an expanding (growing) set of rows

df.expanding().sum()

- df.rolling

Lets us run window functions on a fixed-size window that moves through the data frame

df.rolling(3).mean()

- df.pct_change

For a given data frame, indicates the percentage difference between each cell and the corresponding cell in the previous row

df.pct_change()

- df.diff

For a given data frame, indicates the difference between each cell and the corresponding cell in the previous row

df.diff()

- df.groupby

Allows us to invoke one or more aggregate methods for each value in a particular column.

df.groupby('year')

-  df.loc

Retrieves selected rows and columns

df.loc[:, 'passenger_count'] = df['passenger_count']

- s.iloc

Accesses elements of a series by position

s.iloc[0]

- df.dropna

Removes rows with NaN values

df = df.dropna()

- s.unique

Gets the unique values in a series (Pandas’ drop_duplicates is better)

s.unique()

- df.join

Joins two data frames based on their indexes

df.join(other_df)

- df.merge

Joins two data frames based on any columns

df.merge(other_df)

- df.corr

Shows the correlation between the numeric columns of a data frame

df.corr()

- s.to_frame

Turns a series into a one-column data frame

s.to_frame()

- s.removesuffix

Returns a new string with the same contents as s but without a specified suffix (if it’s there)

s.removesuffix('.csv')

- s.removeprefix

Returns a new string with the same contents as s but without a specified prefix (if it’s there)

s.removeprefix('abcd')

- s.title

Returns a new string based on s in which each word starts with a capital letter

s.title('hello out there')

- pd.concat

Returns one new data frame based on a list of data frames passed to pd.concat

pd.concat([df1, df2, df3])

- df.assign

Adds one or more columns to a data frame

df.assign(a=df['x']*3)

- DataFrame-GroupBy.agg

Applies multiple aggregation methods to a groupby

df.groupby('a')['b'].agg(['mean', 'std'])

- DataFrame-GroupBy.filter

Keeps those rows whose group results in True from an outside function

df.groupby('a').filter(filter_func)

- DataFrameGroupBy.transform

Modifies those rows based on an outside function

df.groupby('a').transform(transform_func)

- df.rename

Renames columns in a data frame

df.rename(columns={'a':'b', 'c':'d'})

- df.drop_duplicates

Returns a data frame whose rows contain distinct values

df.drop_duplicates()

- df.drop

Removes rows or columns from a data frame, returning a new one

df.drop('a', axis='columns')


# Advance grouping joining and sorting 
- s.isnull

Returns a boolean series indicating where there are null (typically NaN) values in the series s

s.isnull()

- df.sort_index

Reorders the rows of a data frame based on the values in its index, in ascending order

df = df.sort_index()

- s.isnull

Returns a boolean series indicating where there are null (typically NaN) values in the series s

s.isnull()

- df.sort_values

Reorders the rows of a data frame based on the values in one or more specified columns

df = df.sort_values('distance')

- df.transpose() or df.T

Returns a new data frame with the same values as df but with the columns and index exchanged

df.transpose() or df.T

- df.expanding

Lets us run window functions on an expanding (growing) set of rows

df.expanding().sum()

- df.rolling

Lets us run window functions on an expanding (growing) set of rows

df.rolling(3).mean()

- df.pct_change

For a given data frame, indicates the percentage difference between each cell and the corresponding cell in the previous row

df.pct_change()

- df.diff

For a given data frame, indicates the difference between each cell and the corresponding cell in the previous row

df.diff()

- df.groupby

Allows us to invoke one or more aggregate methods for each value in a particular column

df.groupby('year')

- df.loc

Retrieves selected rows and columns

df.loc[:, 'passen-ger_count'] = df['passenger_count']

- s.iloc

Accesses elements of a series by position

s.iloc[0]

- df.dropna

Removes rows with NaN values

df = df.dropna()

- s.unique

Gets the unique values in a series (drop_duplicates is better)

s.unique()

- df.join

Joins two data frames based on their indexes

df.join(other_df)

- df.merge

Joins two data frames based on any columns

df.merge(other_df)

- df.corr

Shows the correlation between the numeric columns of a data frame

df.corr()

- s.to_frame

Turns a series into a one-column data frame

s.to_frame()

- s.removesuffix

Returns a new string with the same contents as s but without a specified suffix (if it’s there)

s.removesuffix('.csv')

- s.removeprefix

Returns a new string with the same contents as s but without a specified prefix (if it’s there)

s.removeprefix('abcd')

- s.title

Returns a new string based on s in which each word starts with a capital letter

s.title('hello out there')

- pd.concat

Returns one new data frame based on a list of data frames passed to pd.concat

pd.concat([df1, df2, df3])

- df.assign

Adds one or more columns to a data frame

df.assign(a=df['x']*3)

- DataFrameGroupBy.agg

Applies multiple aggregation methods to a groupby

df.groupby('a')['b'].agg(['mean', 'std'])

- DataFrameGroupBy.filter

Keeps rows whose group results in True from an outside function

df.groupby('a').filter(filter_func)

- DataFrameGroupBy.transform

Modifies rows based on an outside function

df.groupby('a').transform(transform_func)

- df.rename

Renames columns in a data frame

df.rename(columns={'a':'b', 'c':'d'})

- df.drop_duplicates

Returns a data frame whose rows contain distinct values

df.drop_duplicates()

- df.drop

Removes rows or columns from a data frame, returning a new one

df.drop('a', axis='columns')

- example 

```
oecd_df = pd.read_csv('../data/oecd_locations.csv',
                     header=None,
                     names=['abbrev', 'country'],
                     index_col='abbrev')

oecd_tourism_df = pd.read_csv(
    '../data/oecd_tourism.csv',
    usecols=['LOCATION', 'TIME', 'Value'],
    index_col='LOCATION')

tourism_spending = (
    oecd_df
    .join(oecd_tourism_df)
    .groupby('country')['Value'].mean()
)

wine_df = pd.read_csv(
    '../data/winemag-150k-reviews.csv',
    usecols=['country', 'points'])

country_points = (
    wine_df
    .groupby('country')['points'].mean()
)

country_points.sort_values(ascending=False)
country_points.to_frame().join(tourism_spending)
country_points.to_frame().join(tourism_spending,
    how='outer')
country_points.to_frame().join(tourism_spending,
    how='outer').corr()
```


# Midway project 
- pd.MultiIndex
.from_tuples

Returns a multi-index object from a list of tuples

pd.MultiIndex.
from_tuples(a_list)

- str.split

Breaks strings apart, returns a list, and puts extra items on the right

'abc def ghi'.split(None, 1) #
returns ['abc', 'def ghi']

- str.rsplit

Breaks strings apart, returns a list, and puts extra items on the left

'abc def ghi'.rsplit(None, 1) #
returns ['abc def', 'ghi']                    