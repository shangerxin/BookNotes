Prompt engineering for LLMs=John Berryman;Note=Erxin

# Preface
- At their core, LLMs are just text completion engines that mimic the text they see during their training.


# Foundation
- best antidote to hallucinations is “Trust but verify,” just minus the trust.
- LLMs use deterministic tokenizers―which make typos stand out like sore thumbs


# How LLM see the world 
- LLM won’t just answer strings with strings but language with language.



# Moving to Chat
- Base model GPT-3	Predict the next token and complete documents.
- Supervised fine-tuning (SFT) model (derived from base)	Follow directions and chat.
- Reward model (derived from SFT)	Score the quality of completions
- Reinforcement learning from human feedback (derived from SFT and trained by reward model [RM] scores)	Follow directions, chat, and remain helpful, honest, and harmless.

- OpenAI’s chat API in Python:

from openai import OpenAI
client = OpenAI()
response = client.ChatCompletion.create(
  model="gpt-4o",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Tell me a joke."},
  ]
)


# Prompt content 
- Few-shotting scales poorly with context

introduction 
example 
main question 

- Writing a prompt is all about being able to convey a problem to the model along with any relevant context that might help the model address the problem. 

- two main constraints:

Dependency structure
Ensure that any requirements and incompatibilities between elements are respected.

Prompt length
Keep the total prompt length within a set limit, typically your context window size minus the tokens needed for the model’s response.

# Conversational Agency
- example user request modify temperature 

```
from openai import OpenAI

messages = [
    {
        "role": "system",
        "content": "You are HomeBoy, a happy, helpful home assistant.",
    },
    {
        "role": "user",
        "content": "Can you make it a couple of degrees warmer in here?",
    }
]

client = OpenAI()
process_messages(client, messages)
```

Completed but less valuable contents