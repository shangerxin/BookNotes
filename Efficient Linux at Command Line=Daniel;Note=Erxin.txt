Efficient Linux at Command Line=Daniel;Note=Erxin

# Preface 
- The six commands—wc, head, cut, grep, sort, and uniq


    + The wc command prints the number of lines, words, and characters in a file
```   
$ wc --help
Usage: wc [OPTION]... [FILE]...
  or:  wc [OPTION]... --files0-from=F
Print newline, word, and byte counts for each FILE, and a total line if
more than one FILE is specified.  A word is a non-zero-length sequence of
characters delimited by white space.

With no FILE, or when FILE is -, read standard input.

The options below may be used to select which counts are printed, always in
the following order: newline, word, character, byte, maximum line length.
  -c, --bytes            print the byte counts
  -m, --chars            print the character counts
  -l, --lines            print the newline counts
      --files0-from=F    read input from the files specified by
                           NUL-terminated names in file F;
                           If F is - then read names from standard input
  -L, --max-line-length  print the maximum display width
  -w, --words            print the word counts
      --help     display this help and exit
      --version  output version information and exit
```
    

    + The head command prints the first lines of a file.
```
$ head --help
Usage: head [OPTION]... [FILE]...
Print the first 10 lines of each FILE to standard output.
With more than one FILE, precede each with a header giving the file name.

With no FILE, or when FILE is -, read standard input.

Mandatory arguments to long options are mandatory for short options too.
  -c, --bytes=[-]NUM       print the first NUM bytes of each file;
                             with the leading '-', print all but the last
                             NUM bytes of each file
  -n, --lines=[-]NUM       print the first NUM lines instead of the first 10;
                             with the leading '-', print all but the last
                             NUM lines of each file
  -q, --quiet, --silent    never print headers giving file names
  -v, --verbose            always print headers giving file names
  -z, --zero-terminated    line delimiter is NUL, not newline
      --help     display this help and exit
      --version  output version information and exit
```

    + The cut command prints one or more columns from a file.
```
$ cut --help
Usage: cut OPTION... [FILE]...
Print selected parts of lines from each FILE to standard output.

With no FILE, or when FILE is -, read standard input.

Mandatory arguments to long options are mandatory for short options too.
  -b, --bytes=LIST        select only these bytes
  -c, --characters=LIST   select only these characters
  -d, --delimiter=DELIM   use DELIM instead of TAB for field delimiter
  -f, --fields=LIST       select only these fields;  also print any line
                            that contains no delimiter character, unless
                            the -s option is specified
  -n                      (ignored)
      --complement        complement the set of selected bytes, characters
                            or fields
  -s, --only-delimited    do not print lines not containing delimiters
      --output-delimiter=STRING  use STRING as the output delimiter
                            the default is to use the input delimiter
  -z, --zero-terminated    line delimiter is NUL, not newline
      --help     display this help and exit
      --version  output version information and exit

Use one, and only one of -b, -c or -f.  Each LIST is made up of one
range, or many ranges separated by commas.  Selected input is written
in the same order that it is read, and is written exactly once.
Each range is one of:

  N     N'th byte, character or field, counted from 1
  N-    from N'th byte, character or field, to end of line
  N-M   from N'th to M'th (included) byte, character or field
  -M    from first to M'th (included) byte, character or field
  
c option. Print the first three characters from each line of the file, which you can specify either with commas (1,2,3) or as a range (1-3):
```

```
$ cut -c1-3 animals.txt
pyt
sna
alp
```

```
$ grep --help
Usage: grep [OPTION]... PATTERN [FILE]...
Search for PATTERN in each FILE or standard input.
PATTERN is, by default, a basic regular expression (BRE).
Example: grep -i 'hello world' menu.h main.c

Regexp selection and interpretation:
  -E, --extended-regexp     PATTERN is an extended regular expression (ERE)
  -F, --fixed-strings       PATTERN is a set of newline-separated strings
  -G, --basic-regexp        PATTERN is a basic regular expression (BRE)
  -P, --perl-regexp         PATTERN is a Perl regular expression
  -e, --regexp=PATTERN      use PATTERN for matching
  -f, --file=FILE           obtain PATTERN from FILE
  -i, --ignore-case         ignore case distinctions
  -w, --word-regexp         force PATTERN to match only whole words
  -x, --line-regexp         force PATTERN to match only whole lines
  -z, --null-data           a data line ends in 0 byte, not newline

Miscellaneous:
  -s, --no-messages         suppress error messages
  -v, --invert-match        select non-matching lines
  -V, --version             display version information and exit
      --help                display this help text and exit

Output control:
  -m, --max-count=NUM       stop after NUM matches
  -b, --byte-offset         print the byte offset with output lines
  -n, --line-number         print line number with output lines
      --line-buffered       flush output on every line
  -H, --with-filename       print the file name for each match
  -h, --no-filename         suppress the file name prefix on output
      --label=LABEL         use LABEL as the standard input file name prefix
  -o, --only-matching       show only the part of a line matching PATTERN
  -q, --quiet, --silent     suppress all normal output
      --binary-files=TYPE   assume that binary files are TYPE;
                            TYPE is 'binary', 'text', or 'without-match'
  -a, --text                equivalent to --binary-files=text
  -I                        equivalent to --binary-files=without-match
  -d, --directories=ACTION  how to handle directories;
                            ACTION is 'read', 'recurse', or 'skip'
  -D, --devices=ACTION      how to handle devices, FIFOs and sockets;
                            ACTION is 'read' or 'skip'
  -r, --recursive           like --directories=recurse
  -R, --dereference-recursive  likewise, but follow all symlinks
      --include=FILE_PATTERN  search only files that match FILE_PATTERN
      --exclude=FILE_PATTERN  skip files and directories matching FILE_PATTERN
      --exclude-from=FILE   skip files matching any file pattern from FILE
      --exclude-dir=PATTERN  directories that match PATTERN will be skipped.
  -L, --files-without-match  print only names of FILEs containing no match
  -l, --files-with-matches  print only names of FILEs containing matches
  -c, --count               print only a count of matching lines per FILE
  -T, --initial-tab         make tabs line up (if needed)
  -Z, --null                print 0 byte after FILE name

Context control:
  -B, --before-context=NUM  print NUM lines of leading context
  -A, --after-context=NUM   print NUM lines of trailing context
  -C, --context=NUM         print NUM lines of output context
  -NUM                      same as --context=NUM
      --color[=WHEN],
      --colour[=WHEN]       use markers to highlight the matching strings;
                            WHEN is 'always', 'never', or 'auto'
  -U, --binary              do not strip CR characters at EOL (MSDOS/Windows)
  -u, --unix-byte-offsets   report offsets as if CRs were not there
                            (MSDOS/Windows)

'egrep' means 'grep -E'.  'fgrep' means 'grep -F'.
Direct invocation as either 'egrep' or 'fgrep' is deprecated.
```


# Introducing the shell 
- evaluating variables 

Variables like USER and HOME are predefined by the shell. Their values are set automatically when you log in

assign its name to a variable:

$ work=$HOME/Projects

$ cd $work
$ pwd
/home/smith/Projects

define an alias called “less” that runs less -c:2

$ alias less="less -c"

- The shell can redirect input and output in the same command:

$ wc < animals.txt > count

- Any changes you make to $HOME/.bashrc do not affect any running shells. You can force a running shell to reread and execute $HOME/.bashrc with either of the following commands:

.bashrc 
```
# Set the search path
PATH=$HOME/bin:/usr/local/bin:/usr/bin:/bin
# Set the shell prompt
PS1='$ '
# Set your preferred text editor
EDITOR=emacs
# Start in my work directory
cd $HOME/Work/Projects
# Define an alias
alias g=grep
# Offer a hearty greeting
echo "Welcome to Linux, friend!"
```


$ source $HOME/.bashrc                 Uses the builtin "source" command
$ . $HOME/.bashrc                      Uses a dot



# Rerunning commands 
-  “Detecting Duplicate Files”:

$ md5sum *.jpg | cut -c1-32 | sort | uniq -c | sort -nr

- history command, which is a shell builtin.

$ history 


maximum is five hundred or whatever number is stored in the shell variable HISTSIZE, which you can change:

$ echo $HISTSIZE
500
$ HISTSIZE=10000

rerun the most recent grep command, run “bang grep”:
$ !grep


surround the string with question marks as well
$ !?grep?
history | grep -w cd


To mitigate this risk, append the modifier :p to print the command from your history but not execute it:
$ !-3:p

before each deletion:
$ alias rm='rm -i'                  Often found in a shell configuration file
$ rm *.txt
/bin/rm: remove regular file 'a.txt'? y

The prompt changes to indicate an incremental search:
(reverse-i-search)`':

desired command. For example, type c:
(reverse-i-search)`': c

- history expansion with carets 

Suppose you’ve mistakenly run the following command by typing jg instead of jpg:

$ md5sum *.jg | cut -c1-32 | sort | uniq -c | sort -nr

just type the old (wrong) text, the new (corrected) text, and a pair of carets (^), like this:

$ ^jg^jpg

- sed or ed to change a source string into a target string:

s/source/target/

recall a command, such as !!. Then add a colon, and end with a sed-style substitution.

replace jg by jpg (first occurrence only), just as caret notation does, run:

$ !!:s/jg/jpg/


most recent command beginning with md5sum, and perform the same replacement of jg by jpg:

$ !md5sum:s/jg/jpg/

- emacs or vim style command line editing 

If you prefer Vim-style editing, run the following command (or add it to your $HOME/.bashrc file and source it):

$ set -o vi

back to Emacs-style editing, run:

$ set -o emacs

Keystrokes for Emacs- or Vim-style editinga
Action	                                                                Emacs	                        Vim
Move forward by one character                                           Ctrl-f                          l
Move backward by one character                                          Ctrl-b                          h
Move forward by one word                                                Meta-f                          w
Move backward by one word                                               Meta-b                          b
Move to beginning of line                                               Ctrl-a                          0
Move to end of line                                                     Ctrl-e                          $
Transpose (swap) two characters                                         Ctrl-t                          xp
Transpose (swap) two words                                              Meta-t                          n/a
Capitalize word (uppercase first letter)                                Meta-c                         n/a
Uppercase to end of word                                                Meta-u                          n/a
Lowercase to end of word                                                Meta-l                          n/a
Change case of the current character                                    n/a                             ~
Insert the next character verbatim, including control characters        Ctrl-v                          Ctrl-v
Delete forward by one character                                         Ctrl-d                          x
Delete backward by one character                                        Backspace or Ctrl-h             X
Cut forward by one word                                                 Meta-d                          dw
Cut backward by one word                                                Meta-Backspace or Ctrl-w        db
Cut from cursor to beginning of line                                    Ctrl-u                          d^
Cut from cursor to end of line                                          Ctrl-k                          D
Delete the entire line                                                  Ctrl-e Ctrl-u                   dd
Paste (yank) the most recently deleted text                             Ctrl-y                          p
Paste (yank) the next deleted text (after a previous yank)              Meta-y                          n/a
Undo the previous editing operation                                     Ctrl-_                          u
Undo all edits made so far                                              Meta-r                          U
Switch from insertion mode to command mode                              n/a                             Escape
Switch from command mode to insertion mode                              n/a                             i
Abort an edit operation in progress                                     Ctrl-g                          n/a
Clear the display                                                       Ctrl-l                        Ctrl-l



# Crusing the filesystem 
- frequently visited directories using aliases or variables 

$ alias work="cd $HOME/Work/Projects/Web/src/include"

$ work=$HOME/Work/Projects/Web/src/include
$ cd $work
$ pwd

- define a quick cd function 
```
# Define the qcd function
qcd () {
  # Accept 1 argument that's a string key, and perform a different
  # "cd" operation for each key.
  case "$1" in
    work)
      cd $HOME/Work/Projects/Web/src/include
      ;;
    recipes)
      cd $HOME/Family/Cooking/Recipes
      ;;
    video)
      cd /data/Arts/Video/Collection
      ;;
    beatles)
      cd $HOME/Music/mp3/Artists/B/Beatles
      ;;
    *)
      # The supplied argument was not one of the supported keys
      echo "qcd: unknown key '$1'"
      return 1
      ;;
  esac
  # Helpfully print the current directory name to indicate where you are
  pwd
}
# Set up tab completion
complete -W "work recipes video beatles" qcd

$ qcd beatles
```

- configure cd search path 

A cd search path works like your command search path, $PATH, but instead of finding commands, it finds subdirectories. Configure it with the shell variable CDPATH, which has the same format as PATH: a list of directories separated by colons. If your CDPATH consists of these four directories

$HOME:$HOME/Projects:$HOME/Family/Memories:/usr/local

$ CDPATH=/usr     Set a CDPATH
$ cd /tmp         No output: CDPATH wasn't consulted
$ cd bin          cd consults CDPATH...
/usr/bin          ...and prints the new working directory

- Returning to Directories Efficiently

Toggle Between Two Directories with “cd -” 

$ pwd
/home/smith/Finances/Bank/Checking/Statements
$ cd /etc
$ cd -
/home/smith/Finances/Bank/Checking/Statements

Toggle Among Many Directories with pushd and popd

    + view dir stacks 
    
dirs command. It does not modify the stack:

$ dirs
/etc/ssl/certs /etc/apache2 /var/www/html ~/Work/Projects/Web/src

print the stack from top to bottom, use the -p option
$ dirs -p
/etc/ssl/certs
/etc/apache2
/var/www/html
~/Work/Projects/Web/src

Just run pushd twice, once with a dash argument and once without:

$ pushd -
~/Work/Projects/Web/src /etc/ssl/certs /var/www/html /etc/apache2
$ pushd
/etc/ssl/certs ~/Work/Projects/Web/src /var/www/html /etc/apache2

Go deeper into the stack
$ pushd +N


# Next level skills 
# Expanding your toolbox 
- awk and sed

- grep, cut, head, tail, and one handy feature of awk

- Combining files from top to bottom with cat and tac, or side by side with echo and paste diff

- transform text simple commands such as tr and rev

text-producing commands and techniques:

date
Prints dates and times in various formats
$ date +%Y-%m-%d                      Year-Month-Day format

$ seq --help
Usage: seq [OPTION]... LAST
  or:  seq [OPTION]... FIRST LAST
  or:  seq [OPTION]... FIRST INCREMENT LAST
Print numbers from FIRST to LAST, in steps of INCREMENT.
```
$ seq 3 -1 0
3
2
1
0

$ seq -s/ 1 5                 Separate values with forward slashes
1/2/3/4/5

-w makes all values the same width
```

Usage: cut OPTION... [FILE]...
Print selected parts of lines from each FILE to standard output.

Brace expansion
A shell feature that prints a sequence of numbers or characters

find
Prints file paths

yes
Prints the same line repeatedly

$ echo {1..10}                        Forward from 1
1 2 3 4 5 6 7 8 9 10
$ echo {10..1}                        Backward from 10
10 9 8 7 6 5 4 3 2 1
$ echo {01..10}                       With leading zeros (equal width)
01 02 03 04 05 06 07 08 09 10
$ echo {A..Z}
A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
$ echo {A..Z} | tr -d ' '      Delete spaces
ABCDEFGHIJKLMNOPQRSTUVWXYZ
$ echo {A..Z} | tr ' ' '\n'    Change spaces into newlines
A
B
C
⋮
Z

$ ls file[2-4]           Matches existing filenames

Create an alias that prints the nth letter of the English alphabet:
$ alias nth="echo {A..Z} | tr -d ' ' | cut -c"
$ nth 10
J

The find command lists files in a directory recursively, descending into subdirectories and printing full paths
$ find /etc -print            List all of /etc recursively
/etc
/etc/issue.net
/etc/nanorc

$ find . -type f -print               Files only
$ find . -type d -print               Directories only


The yes command prints the same string over and over until terminated
$ yes          Repeats "y" by default
y
y
y ^C           Kill the command with Ctrl-C

$ yes "Efficient Linux" | head -n3            Print a string 3 times

- grep print lines from a file that match a given string


regular expression syntax shared by grep, awk, and sed To match this:	Use this syntax:	Example
Beginning of a line         ^           ^a = Line beginning with a

End of a line               $           !$ = Line ending with an exclamation point

Any single character (except newline)   .       …= Any three consecutive characters

A literal caret, dollar sign, or any other special character  c  \c  \$ = A literal dollar sign

Zero or more occurrences of expression E   E*       _* = Zero or more underscores

Any single character in a set              [characters]     [aeiouAEIOU] = Any vowel

Any single character not in a set          [^characters]    [^aeiouAEIOU] = Any nonvowel

Any character in a given range between c1 and c2   [c1-c2]  [0-9] = Any digit

Any character not in a given range between c1 and c2    [^c1-c2]    [^0-9] = Any nondigit

Either of two expressions E1 or E2    E1\|E2    for grep and sed   one\|two = Either one or two

                                      E1|E2    for awk      one|two = Either one or two

Grouping expression E for precedence   \(E\)    for grep and sed b    \(one\|two\)* = Zero or more occurrences of one or two
                                       (E)    for awk                 (one|two)* = Zero or more occurrences of one or two
                                       
- The tail command prints the last lines of a file—10 lines by default.                                       

head and tail both support a simpler syntax to specify a number of lines without -n.

- You need a command to print the second word on each line, which awk provides with ease:

$ awk '{print $2}' /etc/hosts

awk does not print whitespace between values by default. If you want whitespace, separate the values with commas
```
$ echo Efficient fun Linux | awk '{print $1 $3}'           No whitespace
EfficientLinux
$ echo Efficient fun Linux | awk '{print $1, $3}'          Whitespace
Efficient Linux
```

- df, which prints the amount of free and used disk space on a Linux system:

$ df / /data

- cat, which prints the contents of multiple files to stdout. It’s a joiner of files top-to-bottom

- tac
A bottom-to-top combiner of text files

- paste
A side-by-side combiner of text files。 The paste command combines files side by side in columns separated by a single tab character.

- diff
A command that interleaves text from two files by printing their differences

$ cat file1
Linux is all about efficiency.
I hope you will enjoy this book.
$ cat file2
MacOS is all about efficiency.
I hope you will enjoy this book.
Have a nice day.
$ diff file1 file2
1c1
< Linux is all about efficiency.
---
> MacOS is all about efficiency.
2a3
> Have a nice day.

The notation 2a3 represents an addition. It means that file2 has a third line not present after the second line

- transform their input:

tr
Translates characters into other characters

rev
Reverses characters on a line

awk and sed
General-purpose transformers

$ echo $PATH | tr : "\n"              Translate colons into newlines
/home/smith/bin
/usr/local/bin


- reverse all the lines, cut the first field, and reverse again to achieve your goal

$ rev celebrities | cut -d' ' -f1 | rev

- Add a regular expression to process only the “horse” book:

$ awk -F'\t' '/^horse/{print $4, "(" $3 ").", "\"" $2 "\""}' animals.txt
Siever, Ellen (2009). "Linux in a Nutshell"

awk does much more than print—it can also perform calculations, like summing the numbers 1 to 100:

$ seq 1 100 | awk '{s+=$1} END {print s}'

- $ sed script input-files
or use the -e option to supply multiple scripts that process the input in sequence

s/regexp/replacement/

$ echo Efficient Windows | sed "s/Windows/Linux/"
Efficient Linux
TIP



# Parants children and environments
- The default shell on most Linux systems is bash

Print your current directory name and then run the script:

$ pwd

- Environment Variables

HOME
The path to your home directory. 


PWD
Your shell’s current directory.


EDITOR
The name of (or path to) your preferred text editor.

$ printenv | sort -i | less

- Creating Environment Variables
To turn a local variable into an environment variable, use the export

Children copy from their parents.
For variables like HOME, the values are usually set and exported by your login shell

Different instances read the same configuration files.
Local variables, which are not copied to children, can have their values set in a Linux configuration file such as $HOME/.bashrc

- A child is a partial copy of its parent. It includes copies of its parent’s environment variables

A subshell, in contrast, is a complete copy of its parent.3 It includes all the parent’s variables, aliases, functions, and more

- To check if a shell instance is a subshell, print the variable BASH_SUBSHELL

- configure environment 

startup files 
```
# Place in $HOME/.bash_profile or other personal startup file
if [ -f "$HOME/.bashrc" ]
then
  source "$HOME/.bashrc"
fi
```

initialization files 

cleanup files 

- reread configuration file 

running shell to reread it by sourcing the file

$ source ~/.bash_profile             Uses the builtin "source" command
$ . ~/.bash_profile                  Uses a dot


# More ways to run a command 
- $ grep Nutshell animals.txt

- a conditional list:

$ cp myfile.txt myfile.safe && nano myfile.txt && rm myfile.safe

# If a directory can't be entered, exit with an error code of 1
cd dir || exit 1

$ cd dir || mkdir dir && cd dir || echo "I failed"

 mail -s reminder $USER
 
- a Linux PDF viewer such as okular

- The expression <(…) creates a file descriptor for reading. The related expression >(…) creates a file descriptor for writing

- bash will run that string as a command and exit:

$ bash -c "ls -l"

- piping a command to bash 

$ echo "ls -l" | bash

- start process in background 

$ wc -c my_extremely_huge_file.txt & 

- avoid sort of messiness output of start process in background, redirect stdout to a file, then examine the file at your leisure:

$ sort /usr/share/dict/words | head -n2 > /tmp/results &

- job can't read input in the background, so bring the job into the forground with fg 

$ fg 

- Backgrounding is also great for running a sequence of commands in the background using a conditional list. If any command within the list fails, the rest won’t run and the job completes. 

$ command1 && command2 && command3 &

-  extract the files. A tar command to extract the files is:

$ tar xvf package.tar.gz

- copy files from one directory dir1 to another existing directory dir2 using two tar processes, one writing to stdout and one reading from stdin:

$ tar czf - dir1 | (cd /tmp/dir2 && tar xvf -)

- copy files to an existing directory on another host via SSH:

$ tar czf - dir1 | ssh myhost '(cd /tmp/dir2 && tar xvf -)'

- subshell 

$ echo $BASH_SUBSHELL                  Ordinary execution
0                                      Not a subshell
$ (echo $BASH_SUBSHELL)                Explicit subshell
1                                      Subshell
$ echo $(echo $BASH_SUBSHELL)          Command substitution
1                                      Subshell
$ cat <(echo $BASH_SUBSHELL)           Process substitution
1                                      Subshell
$ bash -c 'echo $BASH_SUBSHELL'        bash -c
0                                      Not a subshell

- process replacement 

Normally when you run a command, the shell runs it in a separate process that is destroyed when the command exits. But exec command, which is a shell builtin. It replaces the running shell (a process) with another command of your choice (another process). 

$ bash                   Run a child shell
$ PS1="Doomed> "         Change the new shell's prompt
Doomed> echo hello       Run any command you like
hello
Doomed> exec ls          ls replaces the child shell, runs, and exits
animals.txt
$ A prompt from the original (parent) shell

If the shell was running in a terminal window, the window closes. If the shell was a login shell, you will be logged out.


# Building a bash one-liner 
- one linear example 

$ paste <(echo {1..10}.jpg | sed 's/ /\n/g') \
        <(echo {0..9}.jpg | sed 's/ /\n/g') \
  | sed 's/^/mv /' \
  | bash
  
$ paste <(echo {1..10}.jpg | sed 's/ /\n/g') \
        <(echo {0..9}.jpg | sed 's/ /\n/g')
1.jpg   0.jpg
2.jpg   1.jpg
⋮
10.jpg  9.jpg

Prepending mv to each line prints a sequence of strings that are mv commands:

$ paste <(echo {1..10}.jpg | sed 's/ /\n/g') \
        <(echo {0..9}.jpg | sed 's/ /\n/g') \
  | sed 's/^/mv /'
mv 1.jpg   0.jpg
mv 2.jpg   1.jpg
⋮
mv 10.jpg  9.jpg

Piping the output to bash executes the mv commands

- know your testing tools 

Insert a tee to view intermediate results.
If you want to view the output (stdout) in the middle of a long pipeline

echo output 

command history 

$ command1 | command2 | command3 | tee outfile | command4 | command5
$ less outfile

- another example 

$ seq -w 10 -1 3 | sed 's/\(.*\)/ch\1.asciidoc/'
ch10.asciidoc
ch09.asciidoc
⋮
ch03.asciidoc

$ paste <(seq -w 10 -1 3 | sed 's/\(.*\)/ch\1.asciidoc/') \
        <(seq -w 11 -1 4 | sed 's/\(.*\)/ch\1.asciidoc/')
ch10.asciidoc   ch11.asciidoc
ch09.asciidoc   ch10.asciidoc
⋮
ch03.asciidoc   ch04.asciidoc


$ paste <(seq -w 10 -1 3 | sed 's/\(.*\)/ch\1.asciidoc/') \
        <(seq -w 11 -1 4 | sed 's/\(.*\)/ch\1.asciidoc/') \
  | sed 's/^/mv /' \
  | bash
  
- checking matched pairs of files 

use cut to strip off their file extensions .txt and .jpg:

$ ls *.jpg | cut -d. -f1
bald_eagle
blue_jay
cardinal


lists with diff using process substitution:
$ diff <(ls *.jpg | cut -d. -f1) <(ls *.txt | cut -d. -f1)
2d1
< blue_jay
3a3
> oriole


full filenames with extensions. Done!
$ ls -1 $(ls *.{jpg,txt} \
  | sed 's/\.[^.]*$//' \
  | uniq -c \
  | awk '/^ *1 /{print $2 ".*"}')
blue_jay.jpg
oriole.txt
yellow.canary.jpg

- generating a CDPATH from your home directory 

CDPATH=$HOME:$HOME/Work:$HOME/Family:$HOME/Finances:$HOME/Linux:$HOME/Music:..

using a subshell to prevent the cd command from changing your shell’s current directory:
$ (cd && ls -d */)
Family/  Finances/  Linux/  Music/  Work/


Adding $HOME/ in front of each directory with sed:
$ (cd && ls -d */) | sed 's/^/$HOME\//g'
$HOME/Family/
$HOME/Finances/
$HOME/Linux/
$HOME/Music/
$HOME/Work/


Let’s use at signs (@) instead of forward slashes so no escaping is needed:
$ (cd && ls -d */) | sed 's@^@$HOME/@g'
$HOME/Family/
$HOME/Finances/
$HOME/Linux/
$HOME/Music/
$HOME/Work/


lop off the final forward slash with another sed expression:
$ (cd && ls -d */) | sed -e 's@^@$HOME/@' -e 's@/$@@'
$HOME/Family
$HOME/Finances
$HOME/Linux

- generating test files 
$ wc -l /usr/share/dict/words
102305 /usr/share/dict/words

few random lines using head:
$ shuf /usr/share/dict/words | head -n3


generate just a single string, and specify the string length (10) as an argument:
$ pwgen -N1 10


$ yes --help
Usage: yes [STRING]...
  or:  yes OPTION
Repeatedly output a line with all specified STRING(s), or 'y'.


$ pwgen --help
Usage: pwgen [ OPTIONS ] [ pw_length ] [ num_pw ]

Options supported by pwgen:
  -c or --capitalize
        Include at least one capital letter in the password
  -A or --no-capitalize
        Don't include capital letters in the password
  -n or --numerals
        Include at least one number in the password
  -0 or --no-numerals
        Don't include numbers in the password
  -y or --symbols
        Include at least one special symbol in the password
  -r <chars> or --remove-chars=<chars>
        Remove characters from the set of characters to generate passwords
  -s or --secure
        Generate completely random passwords
  -B or --ambiguous
        Don't include ambiguous characters in the password
  -h or --help
        Print a help message
  -H or --sha1=path/to/file[#seed]
        Use sha1 hash of given file as a (not so) random generator
  -C
        Print the generated passwords in columns
  -1
        Don't print the generated passwords in columns
  -v or --no-vowels
        Do not use any vowels so as to avoid accidental nasty words
        
        
# Leveraging text files 
- file by name, such as animals.txt:

$ find $HOME -name animals.txt -print

-  find in a large directory tree:

$ grep animals.txt $HOME/.ALLFILES

save the script into a ff script file 

The ff script
```
#!/bin/bash
# $@ means all arguments provided to the script
grep "$@" $HOME/.ALLFILE
```

- Use command substitution to feed the date string from whois to the date command:

$ echo $(whois example.com | grep 'Registry Expiry Date:' | awk '{print $4}')

- awk to find domains that have expired or are expiring today—that is, their expiration date (field 1) is less than or equal to today’s date (printed with date +%Y-%m-%d):

$ awk "\$1<=\"$(date +%Y-%m-%d)\"" expiry.txt

- update pman to search for that unique key first. The vault file, with third column bolded, now looks like:

sally	fake1	google	google.com account

- grep -v to filter any lines that begin with a pound sign:

decrypted=$(gpg -d -q "$DATABASE" | grep -v '^#')


# Extra Goodies 
# Efficiency at the keyboard 
- redirect all output to /dev/null when you first launch the background browser. For example:

$ firefox &> /dev/null

- command produces the needed data for the areacodes.txt file:

$ curl -s https://efficientlinux.com/areacodes.html \
  | hxnormalize -x \
  | hxselect -c -s'@' '#ac .ac, #ac .state, #ac .cities' \
  | sed 's/\([0-9]*\)@\([A-Z][A-Z]\)@\([^@]*\)@/\1\t\2\t\3\n/g'
  
$ sudo apt install html-xml-utils
will install hxnormalize hxselect 

- Both lynx and links download a rendered page with the -dump option. Use whichever program you prefer.

$ lynx -dump https://efficientlinux.com/areacodes.html > tempfile

- access X selections in GNOME’s Terminal (gnome-terminal) and KDE’s Konsole (konsole). If you use a different terminal program

xclip reads stdin and writes the primary selection. It can read from a file:

$ xclip < myfile.txt


# Final time savers 
- Configure default editor 

VISUAL=emacs
EDITOR=emacs

- editing files that contain a given string 

$ vim $(grep -l string *) 

- search large directory trees, use find with xargs instead of grep -r:

$ vim $(find . -type f -print0 | xargs -0 grep -l string) 

```
xargs --help
Usage: xargs [OPTION]... COMMAND [INITIAL-ARGS]...
Run COMMAND with arguments INITIAL-ARGS and more arguments read from input.

Mandatory and optional arguments to long options are also
mandatory or optional for the corresponding short option.
  -0, --null                   items are separated by a null, not whitespace;
                                 disables quote and backslash processing and
                                 logical EOF processing
  -a, --arg-file=FILE          read arguments from FILE, not standard input
  -d, --delimiter=CHARACTER    items in input stream are separated by CHARACTER,
                                 not by whitespace; disables quote and backslash
                                 processing and logical EOF processing
  -E END                       set logical EOF string; if END occurs as a line
                                 of input, the rest of the input is ignored
                                 (ignored if -0 or -d was specified)
  -e, --eof[=END]              equivalent to -E END if END is specified;
                                 otherwise, there is no end-of-file string
  -I R                         same as --replace=R
  -i, --replace[=R]            replace R in INITIAL-ARGS with names read
                                 from standard input, split at newlines;
                                 if R is unspecified, assume {}
  -L, --max-lines=MAX-LINES    use at most MAX-LINES non-blank input lines per
                                 command line
  -l[MAX-LINES]                similar to -L but defaults to at most one non-
                                 blank input line if MAX-LINES is not specified
  -n, --max-args=MAX-ARGS      use at most MAX-ARGS arguments per command line
  -o, --open-tty               Reopen stdin as /dev/tty in the child process
                                 before executing the command; useful to run an
                                 interactive application.
  -P, --max-procs=MAX-PROCS    run at most MAX-PROCS processes at a time
  -p, --interactive            prompt before running commands
      --process-slot-var=VAR   set environment variable VAR in child processes
  -r, --no-run-if-empty        if there are no arguments, then do not run COMMAND;
                                 if this option is not given, COMMAND will be
                                 run at least once
  -s, --max-chars=MAX-CHARS    limit length of command line to MAX-CHARS
      --show-limits            show limits on command-line length
  -t, --verbose                print commands before executing them
  -x, --exit                   exit if the size (see -s) is exceeded
      --help                   display this help and exit
      --version                output version information and exit
```

- crontab launches your default editor and opens an empty file to specify the commands. That file is called your crontab.

Briefly, a scheduled command in a crontab file, often called a cron job, consists of six fields, all on a single (possibly long) line.

 * * * * * command             Run command every minute
30 7 * * * command             Run command at 07:30 every day
30 7 5 * * command             Run command at 07:30 the 5th day of every month
30 7 5 1 * command             Run command at 07:30 every January 5
30 7 * * 1 command             Run command at 07:30 every Monday


sends you an email reminder tomorrow at 10 p.m. to brush your teeth:
$ at 22:00 tomorrow


list your pending at jobs, run atq:
$ atq

- rsync is a smarter copy program. It copies only the differences between the first and second directories.

$ rsync -a dir1/ dir2

- make operates by reading a configuration file, usually named Makefile, that is full of rules and commands.