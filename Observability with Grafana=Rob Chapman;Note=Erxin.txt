Observability with Grafana=Rob Chapman;Note=Erxin


# Introducing observability and the grafana stack 
- telemetry types 

Metrics can be thought of as numeric data that is recorded at a point in time and enriched with labels 

Logs are considered to be unstructured string data types

Distributed traces show the end-to-end journey of an action. They are captured from every step that is taken to complete the action.

Profiling data (stack traces) can give us a very detailed technical view of the system’s use of resources such as CPU cycles 

- Other Grafana tools
Grafana Labs continues to be a leader in observability and has acquired several companies

Other Grafana tools
Grafana Labs continues to be a leader in observability and has acquired several companies

k6 is a load testing tool that provides both a packaged tool to run in your own infrastructure and a cloud Software as a Service

Pyroscope is a recent acquisition of Grafana Labs, joining in March 2023. Pyroscope is a tool that enable teams to engage in the continuous profiling of system resource

Grafana Labs fully embraces its history as an open source software provider. The LGTM stack


# Instrumenting applications and infrastructure 
- Common Event Format (CEF)

CEF is an open logging and auditing format from ArcSight that aims to provide a simple interface to record security-related events.

NCSA Common Log Format (CLF)

The NCSA CLF is historically used on web servers to record information about requests made to the server. This format has been extended by the CLF to include additional information about the browser (user-agent) and the referer.

W3C Extended Log File Format

W3C Extended Log File Format is a log format commonly used by Windows Internet Information Services servers (web servers).

Windows Event Log

Windows Event Log is the standard log format used by the Windows operating system. These logs record events that occur on the system and are categorized System, Application, Security, Setup, and Forwarded events.

JavaScript Object Notation (JSON)

JSON is an open standard file format that is very useful for easily parsing structured log events.

Syslog

Syslog is a standard that’s used across many hardware devices such as networking, compute, and storage, and is used by the Linux kernel for logging.

Logfmt

Logfmt does not have a defined standard but is a widely used form of human-readable structured logging.


- CEF
Developed by ArcSight to fulfill the Security Information and Event Management (SIEM) use case, the CEF is a structured text-based log forma

- Metric protocols
Metric protocols are collections of tools and libraries for instrumenting applications

StatsD 

DogStatsD 

OpenTelemetry Protocol 

Prometheus 

- Tracing, or as it is more commonly referred to, distributed tracing, tracks application requests as they are made between services of a system

The trace record is the parent object that represents the data flow or execution path through the system being observed

OTLP 

Zipkin 

Jaeger 

    + possible impacts to consider:

Increased latency
Memory overhead
Slower startup time

- common infrastructure components 

    + capacity in any area:

System temperature
CPU utilization percent
Overall disk space used and remaining
Memory usage and free memory

    + network devices 
    
Latency
Throughput
Packet loss
Bandwidth

    + powre components 
    
Power supply state
Backup power supply state
Voltage
Wattage
Current


# Grafana Cloud 


# Updating the OpenTelemetry 
- Grafana Loki was designed from the ground up to be a highly scalable multi-tenant logging solution

- LogQL
Grafana developed LogQL as the query language for Loki using the Prometheus Query Language (PromQL) for inspiratio

- Grafana Loki has a full microservices architecture that can be run as a single binary and a simple scalable deployment to a full microservices deployment 

- PromQL offers three data types, which are important, as the functions and operators in PromQL


# Grafana in Practice 
-  Grafana website: https://grafana.com/grafana/plugins/panel-plugins/. A great place to try them out and get ideas you can use in your own dashboards is https://play.grafana.org, 

- OpenTelemetry demo system architecture diagram


# Managing incidents using alerts 
- Golden signals: Golden signals were introduced in the Google SRE book, and they overlap very strongly with RED and USE


# Auotmating collection infrastructure with Helm or Ansible 
- production > collection > storage > visualize 


# Real User Monitoring with Grafana 
- RUM is the term used to describe the collection and processing of telemetry that describes the health of the frontend of your web applications.



# Application performance with grafana pyroscope and k6 
- Smoke tests

These are designed to validate that the system works. They can also be known as sanity or confidence tests. They are called smoke tests after testing a device by powering it on and checking for smoke.

These are designed to quickly say that things look as expected or that something is wrong

These should run quickly, in minutes not hours.

They should be low volume.

Average load tests

These tests show how the system is used in most conditions.

These are designed to simulate the most frequent level of load on the system.

These should run relatively quickly, but slower than smoke tests.

They should simulate average volumes of traffic.

Stress tests

These tests stress the system with higher-than-average peak traffic.

These are designed to simulate what would happen if peak traffic were experienced for an extended duration.

These should run in less than a day.

They should simulate high volumes of traffic.

Spike tests

These tests should show how the system behaves with a sudden, short, massive increase in traffic, as might be seen during a denial of service (DoS) attack.

These are designed to test how the system would handle a sudden overwhelming spike in traffic, such as a DoS attack.

These should run quickly.

They should simulate unrealistic amounts of traffic.

Breakpoint tests

These tests gradually increase traffic until the system breaks down.

These are designed to understand when the system will fail with added load.

These can run for extended periods.

They should simulate steadily increasing rates of traffic.

Soak tests

These tests assess the performance of the system over extended periods. They are like an average load test over a significantly longer period.

These are designed to demonstrate how the system will function during real operations for extended periods. They are good for identifying issues such as memory leaks.

These will run over extended periods such as 48 hours.

They should simulate average volumes of traffic.

- k6 is the load testing tool developed by Grafana Labs after they acquired LoadImpact. k6 offers several key features:


# Using Grafana for fast feedback during the development cycle 
-  life cycle:

Code: This is where new code is written in line with the specification given during the planning phase
Build: This phase is where new code is built
Test: New code is tested in various ways during this phase
Release: The code is verified as ready to be deployed to production in this phase; any final checks or assurances will be performed here
Deploy: The code is deployed to a production environment
Operate: This phase is a continuous phase; the latest deployed release is run in a production environment
Monitor: Any data collected from the release that is currently operating in production is gathered, as well as any feedback or user research, and is collated together to be used in the next planning phase
Plan: During this phase, the team plans what future iterations of the product will contain
Security: This is a continuous concern for the team in a DevSecOps approach and is the responsibility of all members of the team

- The test phase can cover a lot of different test types. While tests are typically managed by the CI/CD platform

- The operate phase is where the product is live in front of customers. The most important aspect of this phase is ensuring customers are getting a great service.

- monitor phase is the phase in which using Grafana can really shine. The two biggest challenges are knowing what telemetry to use to answer a question about the product and whether the telemetry is being made available.

- CI platforms cover a lot of different tools, such as Github Actions, GitLab CI/CD, Jenkins, Azure DevOps, Google Cloud Build, and similar.

- platforms use tools such as Jenkins, GitLab CI/CD, AWS CodeDeploy, ArgoCD, FluxCD

- monitoring these systems:

OpenTelemetry Collector contributed receivers

Prometheus modules: These are modules that allow Prometheus to scrape data from a lot of resource platforms.

- Data collection decicions 

those factors together to help you process them:

Logs:
Choose a log format that can be extended so you can deliver quickly and enhance later.
Select labels carefully, considering Loki’s performance and cardinality. You can always extract additional fields as labels during querying.
Consider whether valuable metrics can be created from logs (to maximize the value).
Metrics:
Identify important metrics, and drop what you don’t need. This can help with metric cardinality, too. If you cannot drop the whole metric, just dropping some of the highest cardinality labels can help a lot.
Choose the protocols that provide the data you need (remember, there are variations, so read the documentation for each carefully).
If using verbose metric protocols, ensure protection is in place (e.g., histogram bucketing) to restrict the ability to flood your system.
Add context so you can correlate metrics with traces.
Traces:
Ensure that the accuracy of spans and traces is implemented and validated
Balance the performance and cost impact with a mitigation strategy (sampling, filtering, and retention)
Instrumentation libraries:
Research them well. If you are using a library, you want it to be maintained and supported going forward.
Telemetry collector:
Run proofs of concept to validate what works with your technology. You don’t want to fall foul of permission constraints restricting the choice of collector on your route to production.
Consider the support model that comes with the collector technology, if any.
What are your business needs from a collector?

- Grafana cloud dashborads 

Top 10 dashboards with errors: This lets you know which dashboards are encountering errors of some form.
Top 10 data sources with errors: This reports the Grafana data sources that have issues. This is useful to diagnose errors with queries, or in communicating to the backend data source.
Top 10 users seeing errors: This identifies your platform users who are encountering problems inside Grafana. This is helpful when investigating platform stability.