Fluent Python, 2nd Edition=Luciano;Note=Erxin

# Preface 
-  Fluent Python is about making the most of Python 3.4
- reference 

https://learning.oreilly.com/library/view/fluent-python-2nd/9781492056348/preface01.html


# Prologue
- special methods __repr__, __abs__, __add__ and __mul__.

import math

class Vector:

    def __init__(self, x=0, y=0):
        self.x = x
        self.y = y

    def __repr__(self):
        return f'Vector({self.x!r}, {self.y!r})'

    def __abs__(self):
        return math.hypot(self.x, self.y)

    def __bool__(self):
        return bool(abs(self))

    def __add__(self, other):
        x = self.x + other.x
        y = self.y + other.y
        return Vector(x, y)

    def __mul__(self, scalar):
        return Vector(self.x * scalar, self.y * scalar)

- collection API 
Collection <- {Sequence {__getitem__, __contains__, __iter__, __reversed__, index},
               Mapping {__getitem__, __contains__, __eq__, __ne__, get, items, keys, values}} ...

- special methods overview 

String/bytes representation
__repr__, __str__, __format__, __bytes__, __fspath__


Conversion to number
__abs__, __bool__, __complex__, __int__, __float__, __hash__, __index__


Emulating collections
__len__, __getitem__, __setitem__, __delitem__, __contains__


Iteration
__iter__, __aiter__, __next__, __anext__, __reversed__

Callable or coroutine execution
__call__, __await__


Context management
__enter__, __aenter__, __exit__, __aexit__


Instance creation and destruction
__new__, __init__, __del__


Attribute management
__getattr__, __getattribute__, __setattr__, __delattr__, __dir__


Attribute descriptors
__get__, __set__, __delete__, __set_name__


Class services
__prepare__, __init_subclass__, __instancecheck__, __subclasscheck__


Unary numeric operators
__neg__ -, __pos__ +, __abs__ abs()


Rich comparison operators
__lt__ <, __le__ <=, __eq__ ==, __ne__ !=, __gt__ >, __ge__ >=


Arithmetic operators
__add__ +, __sub__ -, __mul__ *, __truediv__ /, __floordiv__ //, __mod__ %, __divmod__ divmod() , __pow__ ** or pow(), __round__ round(), __matmul__ @


Reversed arithmetic operators
__radd__, __rsub__, __rmul__, __rtruediv__, __rfloordiv__, __rmod__, __rdivmod__, __rpow__, __rmatmul__


Augmented assignment arithmetic operators
__iadd__, __isub__, __imul__, __itruediv__, __ifloordiv__, __imod__, __ipow__, __imatmul__


Bitwise operators
__invert__ ~, __lshift__ <<, __rshift__ >>, __and__ &, __or__ |, __xor__ ^


Reversed bitwise operators
__rlshift__, __rrshift__, __rand__, __rxor__, __ror__


Augmented assignment bitwise operators
__ilshift__, __irshift__, __iand__, __ixor__, __ior__

- len is not called as a method because it gets special treatment as part of the Python Data Model, just like abs. But thanks to the special method __len__, you can also make len work with your own custom objects


# An Array of Sequences
- built-in sequences 

list, tuple, and collections.deque 

- flat sequences 

str, bytes, bytearray, memoryview, and array.array 

- mutable sequences 

list, bytearray, array.array, collections.deque, and memoryview

- immutable sequences 

tuple, str, and bytes 

- list compare and local scope within 

>>> a in <list>

>>> x = 'ABC'>>> codes = [ord(x) for x in x]

- generator expression 

>>> symbols = '$¢£¥€¤'
>>> tuple(ord(symbol) for symbol in symbols)  1
(36, 162, 163, 165, 8364, 164)
>>> import array
>>> array.array('I', (ord(symbol) for symbol in symbols))  2
array('I', [36, 162, 163, 165, 8364, 164])


>>> a, b, *rest = range(5)
>>> a, b, rest
(0, 1, [2, 3, 4])

- nested tuple unpacking 

metro_areas = [
    ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)),   1
    ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)),
    ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)),
    ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)),
    ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)),
]

print('{:15} | {:^9} | {:^9}'.format('', 'lat.', 'long.'))
fmt = '{:15} | {:9.4f} | {:9.4f}'
for name, cc, pop, (latitude, longitude) in metro_areas:  2
    if longitude <= 0:  3
        print(fmt.format(name, latitude, longitude))

- slice, slice(start, stop, step)
>>> l = [10, 20, 30, 40, 50, 60]
>>> l[:2]  # split at 2
[10, 20]
>>> l[2:]

- slice object, : s[a:b:c] can be used to specify a stride or step c, causing the resulting slice to skip item

>>> s = 'bicycle'
>>> s[::3]
'bye'
>>> s[::-1]
'elcycib'
>>> s[::-2]
'eccb'

- using + and * 

>>> a = [1, 2, 3]
>>> a * 5
[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]
>>> 5 * 'abcd'
'abcdabcdabcdabcdabcd'

- augmented assignment with sequences 

+= also applies to *=, which is implemented via __imul__. The __iadd__ and __imul__ special methods are discussed in [Link to Come].
 
- list.sort and the sorted Built-In Function

The list.sort method sorts a list in-place—that is, without making a copy.

random.shuffle(s) function, which shuffles the mutable sequence s in-place, and returns None.

- managing ordered sequences with bisect, The bisect module offers two main functions—bisect and insort—that use the binary search algorithm to quickly find and insert items

bisect(haystack, needle) does a binary search for needle in haystack—which must be a sorted sequence

locate the position where needle can be inserted while maintaining haystack in ascending order

```
import bisect
import sys

HAYSTACK = [1, 4, 5, 6, 8, 12, 15, 20, 21, 23, 23, 26, 29, 30]
NEEDLES = [0, 1, 2, 5, 8, 10, 22, 23, 29, 30, 31]

ROW_FMT = '{0:2d} @ {1:2d}    {2}{0:<2d}'

def demo(bisect_fn):
    for needle in reversed(NEEDLES):
        position = bisect_fn(HAYSTACK, needle)  
        offset = position * '  |'  
        print(ROW_FMT.format(needle, position, offset))  

if __name__ == '__main__':

    if sys.argv[-1] == 'left':    
        bisect_fn = bisect.bisect_left
    else:
        bisect_fn = bisect.bisect

    print('DEMO:', bisect_fn.__name__)  
    print('haystack ->', ' '.join('%2d' % n for n in HAYSTACK))
    demo(bisect_fn)
```

- inserting with bisect.insort, inserting items in sorted sequences, as the following section shows.

```
import bisect
import random

SIZE = 7

random.seed(1729)

my_list = []
for i in range(SIZE):
    new_item = random.randrange(SIZE * 2)
    bisect.insort(my_list, new_item)
    print(f'{new_item:2d} -> {my_list}')
```

- Arrays, If a list will only contain numbers, an array.array is more efficient: it supports all mutable sequence operations (including .pop, .insert, and .extend), and additional methods for fast loading and saving such as .frombytes and .tofile.

>>> from array import array  
>>> from random import random
>>> floats = array('d', (random() for i in range(10**7)))  
>>> floats[-1]  
0.07802343889111107
>>> fp = open('floats.bin', 'wb')
>>> floats.tofile(fp)  
>>> fp.close()
>>> floats2 = array('d')  
>>> fp = open('floats.bin', 'rb')
>>> floats2.fromfile(fp, 10**7)  
>>> fp.close()
>>> floats2[-1]  
0.07802343889111107
>>> floats2 == floats  
True

- memory views,  inspired by the NumPy library (which we’ll discuss shortly in “NumPy”). Travis Oliphant, lead author of NumPy. the memoryview.cast method lets you change the way multiple bytes are read or written as units without moving bits around.

>> from array import array
>>> octets = array('B', range(6))  
>>> m1 = memoryview(octets)  
>>> m1.tolist()
[0, 1, 2, 3, 4, 5]
>>> m2 = m1.cast('B', [2, 3])  
>>> m2.tolist()
[[0, 1, 2], [3, 4, 5]]
>>> m3 = m1.cast('B', [3, 2])  
>>> m3.tolist()
[[0, 1], [2, 3], [4, 5]]
>>> m2[1,1] = 22  
>>> m3[1,1] = 33  
>>> octets  
array('B', [0, 1, 2, 33, 22, 5])

- NumPy is so awesome that a detour is warranted.

- standard packages implement queues 

deque 
queue 
mutiprocessing, SimpleQueue, Queue, JoinableQueue 
asyncio, Queue, LifoQueue, PriorityQueue, JoinableQueue 
heapq


# Dictionary and sets 
- built-in functions are all in __builtins__.__dict__.

>>> a = dict(one=1, two=2, three=3)
>>> b = {'three': 3, 'two': 2, 'one': 1}

- dict comparehensions 

A dictcomp builds a dict instance by taking key:value pairs from any iterable.

collections.defaultdict to provide another elegant solution to the problem, defaultdict is configured to create items on demand whenever a missing key is searched 

```
import sys
import re
import collections

WORD_RE = re.compile(r'\w+')

index = collections.defaultdict(list)     
with open(sys.argv[1], encoding='utf-8') as fp:
    for line_no, line in enumerate(fp, 1):
        for match in WORD_RE.finditer(line):
            word = match.group()
            column_no = match.start()+1
            location = (line_no, column_no)
            index[word].append(location)  

# print in alphabetical order
for word in sorted(index, key=str.upper):
    print(word, index[word])
```

Create a defaultdict with the list constructor as default_factory.

If word is not initially in the index, the default_factory is called to produce the missing value, which in this case is an empty list that is then assigned to index[word]. .append(location) operation always succeeds 

- user-defined mapping type is to subclass collections.UserDict instead of dict

- collections.OrderedDict Maintains keys in insertion order, allowing iteration over items in a predictable order. 

- collections.ChainMap Holds a list of mappings that can be searched as one. The lookup is performed on each mapping in order

- collections.Counter A mapping that holds an integer count for each key. 

```
>>> ct = collections.Counter('abracadabra')
>>> ct
Counter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1})
>>> ct.update('aaaaazzz')
>>> ct
Counter({'a': 10, 'z': 3, 'b': 2, 'r': 2, 'c': 1, 'd': 1})
>>> ct.most_common(3)
[('a', 10), ('z', 3), ('b', 2)]
```

- building custom mappings 

collection.UserDict, it is implemented in python not as same as dict which is implemented in C 

typing.TypedDict 

- collection.UserDict worth to noting method 

MutableMapping.update,  This powerful method can be called directly but is also used by __init__ to load the instance from other mappings

Mapping.get, obtain results consistent with __getitem__

- Python 3.3, the types module provides a wrapper class called MappingProxyType, which, given a mapping, returns a mappingproxy instance that is a read-only

- dictionary views, The dict instance methods .keys(), .values(), and .items() return instances of classes called dict_keys, dict_values, and dict_items

- In Python 3, the standard string representation of sets always uses the {…} notation

s ^ z, s.__xor__(z), symmetric difference 
 	

z ^ s, s.__rxor__(z)

s ^= z, s.__ixor__(z) s updated with symmetric difference of s and z

- set operations on dict views 

- performance experiment, how the size of a dict, set, or list affects the performance

1,000 1× 0.099ms 1.00×

- The hash() built-in function works directly with built-in types and falls back to calling __hash__ for user-defined types

Python then probes the next bucket and finds it empty. So 'Wed' ends up at index 4


# Text versus bytes 
- bytes, bytearray, memory view 

- decoder, legacy 8-bit encodings like 'cp1252', 'iso8859_1', and 'koi8_r' are able to decode any stream of bytes

- encode 

>>> u16le = 'El Niño'.encode('utf_16le')
>>> list(u16le)
[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]
>>> u16be = 'El Niño'.encode('utf_16be')
>>> list(u16be)
[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111]

- handle text file using the unicode sandwich 
    1. bytes -> str, decode bytes on input 
    2. process text only 
    3. encode text on output 


    + bug example 
    >>> open('cafe.txt', 'w', encoding='utf_8').write('café')
4
>>> open('cafe.txt').read()
'cafÃ©'

Windows default file encoding—code page 1252—and the trailing bytes in the file were decoded as characters 'Ã©' instead of 'é'.

- check default encoding 
```
import sys, locale

expressions = """
        locale.getpreferredencoding()
        type(my_file)
        my_file.encoding
        sys.stdout.isatty()
        sys.stdout.encoding
        sys.stdin.isatty()
        sys.stdin.encoding
        sys.stderr.isatty()
        sys.stderr.encoding
        sys.getdefaultencoding()
        sys.getfilesystemencoding()
    """

my_file = open('dummy', 'w')

for expression in expressions.split():
    value = eval(expression)
    print(expression.rjust(30), '->', repr(value))
```

- two normalization forms—NFKC and NFKD—the letter K stands for “compatibility.” These are stronger forms of normalization

- sorting with the unicode collection 

https://pypi.python.org/pypi/pyuca/

Unicode Collation Algorithm (UCA)

>>> import pyuca
>>> coll = pyuca.Collator()
>>> fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
>>> sorted_fruits = sorted(fruits, key=coll.sort_key)
>>> sorted_fruits
['açaí', 'acerola', 'atemoia', 'cajá', 'caju']

- finding characters by name 

The unicodedata module has functions to retrieve character metadata, including unicodedata.name()


# Record-like data structures 
- three builders 

collections.namedtuple 

typing.NamedTuple: an alternative that allows type annotations on the fields

@dataclasses.dataclass: a class decorator that allows more customization than previous alternatives

__init__, __repr__, and __eq__ methods automatically, as well as other useful features

```
>>> from collections import namedtuple
>>> Coordinate = namedtuple('Coordinate', 'lat long')
>>> issubclass(Coordinate, tuple)
True
>>> moscow = Coordinate(55.756, 37.617)
>>> moscow
Coordinate(lat=55.756, long=37.617)  1
>>> moscow == Coordinate(lat=55.756, long=37.617)  2
True
```

typing.NamedTuple provides the same funcionality, adding a type annotation to each field

- variable notation sytnax 

var_name: some_type

var_name: some_type = a_value

    + example 
``` 
class DemoPlainClass:

    a: int           
    b: float = 1.1   
    c = 'spam'       
```

a becomes an annotation, but is otherwise discarded.
b is saved as an annotation, and also becomes a class attribute with value 1.1.
c is just a plain old class attribute, not an annotation.

None of those three attributes will be in a new instance of DemoPlainClass. If you create an object o = DemoPlainClass(), o.a will raise AttributeError, while o.b and o.c will retrieve the class attributes with values 1.1 and 'spam'—that’s just normal Python object behavior.

means a and b will work as read-only instance attributes—which makes sense when we recall that DemoNTClass instances are just a fancy tuples

- @dataclass 

@dataclass(*, init=True, repr=True, eq=True, order=False,
              unsafe_hash=False, frozen=False)

Python objects, it’s not too hard for a nosy programmer to go around the protection afforded by frozen=True.


# Object references, mutability and recycling 
- == and is

The == operator compares the values of objects (the data they hold), while is compares their identities

- copies are shallow by default 

- Weak references to an object do not increase its reference count. The object that is the target of a reference is called the referent. 

>>> import weakref
>>> a_set = {0, 1}
>>> wref = weakref.ref(a_set)  1
>>> wref
<weakref at 0x100637598; to 'set' at 0x100636748>
>>> wref()  2

    + not every python object can be weak referenced. Basic list and dict instances may not be referents, but a plain subclass of either can solve this problem 

- WeakValueDictionary skit, The class WeakValueDictionary implements a mutable mapping where the values are weak references to objects. 


# Functions as object 
- higher-order functions are map, filter, reduce

- functools 

>>> from functools import reduce  1
>>> from operator import add  2
>>> reduce(add, range(100))  3
4950
>>> sum(range(100))  4
4950
>>>

- nine flavors of callable object 

user defined functions 

built-in functions 

built-in methods, dict.get 

methods, function defined in the body of class 

classes 

class instances 

generator functions, use yield keyword in their body 

native coroutine functions, defined with async, 

asynchronouns generator functions, defined with async and have yeild in their body. generator for use with async for

- freezing arguments with functools.partial 

The functools module provides several higher-order functions. The best known of them is probably reduce


# Type hints in functions 
- typing, Any type, also known as the dynamic type. When a type checker sees an untyped function like this

def double(n: Any) -> Any:
    return n * 2
    
- optional and union types 

from typing import Optional

def show_count(count: int, singular: str, plural: Optional[str] = None) -> str:

- collection types and type hints

list
typing.List


set
typing.Set


frozenset
typing.FrozenSet


collections.deque
typing.Deque


collections.abc.MutableSequence
typing.MutableSequence


collections.abc.Sequence
typing.Sequence


collections.abc.Collection
typing.Collection


collections.abc.Container
typing.Container


collections.abc.Set
typing.AbstractSet


collections.abc.MutableSet
typing.MutableSet

- mapping types, views and their type hints

dict
typing.Dict

collections.defaultdict
typing.DefaultDict

collections.OrderedDict
typing.OrderedDict

collections.Counter
typing.Counter

collections.ChainMap
typing.ChainMap

collections.abc.Mapping
typing.Mapping

collections.abc.MutableMapping
typing.MutableMapping

collections.abc.MappingView
typing.MappingView

collections.abc.KeysView
typing.KeysView

collections.abc.ItemsView
typing.ItemsView

collections.abc.ValuesView
typing.ValuesView

- type dict 

from typing import TypedDict, List
import json

class BookDict(TypedDict):
    isbn: str
    title: str
    authors: List[str]
    pagecount: int

- abstract base classes 

collections.abc. Ideally, a function should accept arguments of those abstract types

A similar comment appears in the entries for typing.Dict and typing.Set.

- iterable, The typing.List documentation I just quoted recommends Sequence and Iterable for function parameter type hints

- typevar with constraints

from typing import Iterable, TypeVar
from decimal import Decimal
from fractions import Fraction

NumberT = TypeVar('NumberT', float, Decimal, Fraction)

def mode(data: Iterable[NumberT]) -> NumberT:

- bounded typevar 

from typing import Iterable, Hashable

def mode(data: Iterable[Hashable]) -> Hashable:

- protocols, similar to interface 

In Python, a protocol definition is written as a typing.Protocol subclass. However, classes that implement a protocol don’t need to inherit

```
from typing import Protocol, Any

class Comparable(Protocol):  1
    def __lt__(self, other: Any) -> bool: ...  

from typing import TypeVar, Iterable, List
from comparable import Comparable

CT = TypeVar('CT', bound=Comparable)

def top(series: Iterable[CT], length: int) -> List[CT]:
    ordered = sorted(series, reverse=True)
    return ordered[:length]
```

- no return

def exit(__status: object = ...) -> NoReturn: ...

- overload signature 
```
@overload
def sum(__iterable: Iterable[_T]) -> Union[_T, int]: ...
@overload
def sum(__iterable: Iterable[_T], start: _S) -> Union[_T, _S]: ...


from functools import reduce  1
from operator import add
from typing import overload, Iterable, Union, TypeVar

T = TypeVar('T')
S = TypeVar('S')  2

@overload
def sum(it: Iterable[T]) -> Union[T, int]: ...  3
@overload
def sum(it: Iterable[T], /, start: S) -> Union[T, S]: ...  4
def sum(it, /, start=0):  5
    return reduce(add, it, start)
```

- annotating positional-only and variadic parameters 

def tag(name, /, *content, class_=None, **attrs):

The type hint for the arbitrary keyword arguments is **attrs: str. In this example, the type of attrs will be Dict[str, str]

At runtime, as a module is loaded, Python reads the type hints in functions, classes and modules and stores them in attributes named __annotations__


# Decorators and closures 
- Coverage of the functools.lru_cache decorator was updated to include “Simplified usage of lru_cache in Python 3.8”.

- decorators 

@decorate
def target():
    print('running target()')

    + example 
    
import time


def clock(func):
    def clocked(*args):  1
        t0 = time.perf_counter()
        result = func(*args)  2
        elapsed = time.perf_counter() - t0
        name = func.__name__
        arg_str = ', '.join(repr(arg) for arg in args)
        print(f'[{elapsed:0.8f}s] {name}({arg_str}) -> {result!r}')
        return result
    return clocked  


    + functools 
    
import time
import functools


def clock(func):
    @functools.wraps(func)
    def clocked(*args, **kwargs):
        t0 = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = time.perf_counter() - t0
        name = func.__name__
        arg_lst = []
        if args:
            arg_lst.append(', '.join(repr(arg) for arg in args))
        if kwargs:
            pairs = [f'{k}={v!r}' for k, v in kwargs.items()]
            arg_lst.append(', '.join(pairs))
        arg_str = ', '.join(arg_lst)
        print(f'[{elapsed:0.8f}s] {name}({arg_str}) -> {result!r}')
        return result
    return clocked

- memoization with functools.lru_cache 


import functools

from clockdeco import clock


@functools.lru_cache  1
@clock  2
def fibonacci(n):
    if n < 2:
        return n
    return fibonacci(n-2) + fibonacci(n-1)


if __name__ == '__main__':
    print(fibonacci(6))

- single dispatch generic functions 

import html

def htmlize(obj):
    content = html.escape(repr(obj))
    return f'<pre>{content}</pre>'

The @singledispatch decorator is very different. It’s a runtime feature.

functools.singledispatch exists since Python 3.4, but it only supports type hints since Python 3.7

@singledispatch marks the base function that handles the object type.

```
from functools import singledispatch
from collections import abc
import fractions
import decimal
import html
import numbers

@singledispatch  1
def htmlize(obj: object) -> str:
    content = html.escape(repr(obj))
    return f'<pre>{content}</pre>'

@htmlize.register  2
def _(text: str) -> str:  3
    content = html.escape(text).replace('\n', '<br>\n')
    return f'<p>{content}</p>'

@htmlize.register  4
def _(seq: abc.Sequence) -> str:
    inner = '</li>\n<li>'.join(htmlize(item) for item in seq)
    return '<ul>\n<li>' + inner + '</li>\n</ul>'

@htmlize.register  5
def _(n: numbers.Integral) -> str:
    return f'<pre>{n} (0x{n:x})</pre>'

@htmlize.register  6
def _(n: bool) -> str:
    return f'<pre>{n}</pre>'

@htmlize.register(fractions.Fraction)  7
def _(x) -> str:
    frac = fractions.Fraction(x)
    return f'<pre>{frac.numerator}/{frac.denominator}</pre>'

@htmlize.register(decimal.Decimal)  8
@htmlize.register(float)
def _(x) -> str:
    frac = fractions.Fraction(x).limit_denominator()
    return f'<pre>{x} ({frac.numerator}/{frac.denominator})</pre>'
```
    
A single class with many overloaded variations of a method is better than a single function with a lengthy stretch of if/elif/elif/elif blocks. But both solutions are flawed because they concentrate too much responsibility in a single code unit
    
The advantage of @singledispath is supporting modular extension: each module can register a specialized function for each type it supports. 
    
- parameterized decorators 
    
registry = set()  1

def register(active=True):  2
    def decorate(func):  3
        print('running register'
              f'(active={active})->decorate({func})')
        if active:   4
            registry.add(func)
        else:
            registry.discard(func)  5

        return func  6
    return decorate  7

@register(active=False)  8
def f1():
    print('running f1()')

@register()  9
def f2():
    print('running f2()')

def f3():
    print('running f3()')
    
- parameterized clock decorator 
    
import time

DEFAULT_FMT = '[{elapsed:0.8f}s] {name}({args}) -> {result}'

def clock(fmt=DEFAULT_FMT):  1
    def decorate(func):      2
        def clocked(*_args): 3
            t0 = time.perf_counter()
            _result = func(*_args)  4
            elapsed = time.perf_counter() - t0
            name = func.__name__
            args = ', '.join(repr(arg) for arg in _args)  5
            result = repr(_result)  6
            print(fmt.format(**locals()))  7
            return _result  8
        return clocked  9
    return decorate  10

if __name__ == '__main__':

    @clock()  11
    def snooze(seconds):
        time.sleep(seconds)

    for i in range(3):
        snooze(.123)
        
- a class based clock decorator 

import time

DEFAULT_FMT = '[{elapsed:0.8f}s] {name}({args}) -> {result}'

class clock:  1

    def __init__(self, fmt=DEFAULT_FMT):  2
        self.fmt = fmt

    def __call__(self, func):  3
        def clocked(*_args):
            t0 = time.perf_counter()
            _result = func(*_args)  4
            elapsed = time.perf_counter() - t0
            name = func.__name__
            args = ', '.join(repr(arg) for arg in _args)
            result = repr(_result)
            print(self.fmt.format(**locals()))
            return _result
        return clocked


# Design patterns with first class functions 
- context 
- strategy 
- concrete strategy 
- function-oriented strategy 

import typing
from typing import Sequence, Optional, Callable


class Customer(typing.NamedTuple):
    name: str
    fidelity: int


class LineItem:
    def __init__(self, product: str, quantity: int, price: float):
        self.product = product
        self.quantity = quantity
        self.price = price

    def total(self):
        return self.price * self.quantity


class Order:  # the Context
    def __init__(
        self,
        customer: Customer,
        cart: Sequence[LineItem],
        promotion: Optional[Callable[['Order'], float]] = None,
    ) -> None:
        self.customer = customer
        self.cart = list(cart)
        self.promotion = promotion

    def total(self) -> float:
        if not hasattr(self, '__total'):
            self.__total = sum(item.total() for item in self.cart)
        return self.__total

    def due(self) -> float:
        if self.promotion is None:
            discount = 0.0
        else:
            discount = self.promotion(self)  1
        return self.total() - discount

    def __repr__(self):
        fmt = '<Order total: {:.2f} due: {:.2f}>'
        return fmt.format(self.total(), self.due())

- globals() Return a dictionary representing the current global symbol table. 


# Classes and protocols 
- object representations
repr() Return a string representing the object as the developer wants to see it.

str() Return a string representing the object as the user wants to see it.

methods __repr__ and __str__ support repr() and str(), as we saw in Chapter 1.

- vector class redux 

Class method is modified by the classmethod decorator.

The classmethod decorator is not mentioned in the Python tutorial, and neither is staticmethod

classmethod. Example 11-3 shows its use: to define a method that operates on the class and not on instances. classmethod changes the way the method is called, so it receives the class itself as the first argument, instead of an instance
    
>>> class Demo:
...     @classmethod
...     def klassmeth(*args):
...         return args  1
...     @staticmethod
...     def statmeth(*args):
...         return args  2
...
>>> Demo.klassmeth()  3
(<class '__main__.Demo'>,)
>>> Demo.klassmeth('spam')
(<class '__main__.Demo'>, 'spam')
>>> Demo.statmeth()   4
()
>>> Demo.statmeth('spam')
('spam',)

- hashable, Implementing __hash__ and __eq__ correctly is all it takes.
- private attribute, Private attribute names are “mangled” by prefixing the _ and the class name
- “protect” attributes by convention (e.g., self._x
- If you are dealing with millions of instances with few attributes, the __slots__ class attribute can save a lot of memory, by letting the interpreter store the instance attributes in a tuple instead of a dict

A __slots__ attribute defined in a class is not inherited by subclasses. 

the __slots__ list, your instances will keep attributes named in __slots__ in the per-instance tuple

    + You must remember to redeclare __slots__ in each subclass

    + Instances will only be able to have the attributes listed in __slots__

    + Instances cannot be targets of weak references unless you remember to include '__weakref__' in __slots__
    
    
# Sequence hacking hashing and slicing 
- implement Vector 

from array import array
import reprlib
import math


class Vector:
    typecode = 'd'

    def __init__(self, components):
        self._components = array(self.typecode, components)  1

    def __iter__(self):
        return iter(self._components)  2

    def __repr__(self):
        components = reprlib.repr(self._components)  3
        components = components[components.find('['):-1]  4
        return 'Vector({})'.format(components)

    def __str__(self):
        return str(tuple(self))

    def __bytes__(self):
        return (bytes([ord(self.typecode)]) +
                bytes(self._components))  5

    def __eq__(self, other):
        return tuple(self) == tuple(other)

    def __abs__(self):
        return math.sqrt(sum(x * x for x in self))  6

    def __bool__(self):
        return bool(abs(self))

    @classmethod
    def frombytes(cls, octets):
        typecode = chr(octets[0])
        memv = memoryview(octets[1:]).cast(typecode)
        return cls(memv)  


# interfaces, protocols, abcs 
- typing maps 

duck typing, python's default 

goose typing, abstract base classes since python 2.6, goose typing means is: isinstance(obj, cls) is now just fine

static typing, like c and java, using the typing module 

static duck typing, using the typing.Protocol new in python 3.8 

- fail fast, defensive programming 

- abc syntax 

@abstractmethod, the abc module defines the @abstractclassmethod, @abstractstaticmethod, and @abstractproperty 

- __subclasshook__ allows ABCs to support structural typing. You can formalize an interface with an ABC, you can make isinstance checks against that ABC

- static protocols 

```
from typing import TypeVar, Protocol

T = TypeVar('T')  1

class Repeatable(Protocol):
    def __mul__(self: T, repeat_count: int) -> T: ...  2

RT = TypeVar('RT', bound=Repeatable)  3

def double(x: RT) -> RT:  4
    return x * 2
```
 
- typing.Protocol subclass, you can use the @runtime_checkable decorator to make that protocol support isinstance/issubclass checks at runtime

```
@runtime_checkable
class SupportsComplex(Protocol):
    """An ABC with one abstract method __complex__."""
    __slots__ = ()

    @abstractmethod
    def __complex__(self) -> complex:
        pass
```

- the numbers abcs and numeric protocols 

opmost ABC, Complex is its immediate subclass, and so on, down to Integral:

Number

Complex

Real

Rational

Integral



# inheritance for good for worse 
- provide aggregate classes to users 
- don't subclass from more than one concrete class 
- subclasing built-in types is tricky 
- __init__ and __update__ methods 

```
>>> class DoppelDict(dict):
...     def __setitem__(self, key, value):
...         super().__setitem__(key, [value] * 2)  
...
>>> dd = DoppelDict(one=1)  
>>> dd
{'one': 1}
>>> dd['two'] = 2  
>>> dd
{'one': 1, 'two': [2, 2]}
>>> dd.update(three=3)  
>>> dd
{'three': 3, 'one': 1, 'two': [2, 2]}
```
- distinguish interface inheritance from implementation inheritance 
- provide aggregate classes to users 


# More about type hints 
- typing.TypedDict for type hinting dicts used as records

- @typing.overload allows annotating each different combination

- takeaways from overloading max 

- TypedDict to protect against errors while handling dynamic data structures like JSON API responses

```
from typing import TypedDict
import json

class BookDict(TypedDict):
    isbn: str
    title: str
    authors: list[str]
    pagecount: int
```

- type casting 

The typing.cast() special function provides one way to handle type checking malfunctions or incorrect type hints


- contravariant 

```
from typing import TypeVar, Generic

class Refuse:  
    """Any refuse."""

class Biodegradable(Refuse):
    """Biodegradable refuse."""

class Compostable(Biodegradable):
    """Compostable refuse."""

T_contra = TypeVar('T_contra', contravariant=True)  

class TrashCan(Generic[T_contra]):  
    def put(self, refuse: T_contra) -> None:
        """Store trash until dumped."""

def deploy(trash_can: TrashCan[Biodegradable]):
    """Deploy a trash can for biodegradable refuse."""
```

A contravariant container is usually a write-only data structure, also known as a “sink”.



# Operator overloading, doing it right 
- limitations 

We cannot overload operators for the built-in types.

We cannot create new operators, only overload existing ones.

A few operators can’t be overloaded: is, and, or, not (but the bitwise &, |, ~, can).

- unary operators 

__neg__ 

__pos__ 

__invert__ 

- using @ as an infix operator 

The @ operator is supported by the special methods __matmul__, __rmatmul__, and __imatmul__

```
>>> va = Vector([1, 2, 3])
>>> vz = Vector([5, 6, 7])
>>> va @ vz == 38.0  # 1*5 + 2*6 + 3*7
True
>>> [10, 20, 30] @ vz
380.0
>>> va @ 3
Traceback (most recent call last):
...
TypeError: unsupported operand type(s) for @: 'Vector' and 'int'
```


# Iterables, iterators and generators 
- a sequence of words 
import re
import reprlib

RE_WORD = re.compile(r'\w+')


class Sentence:

    def __init__(self, text):
        self.text = text
        self.words = RE_WORD.findall(text)  

    def __getitem__(self, index):
        return self.words[index]  

    def __len__(self):  
        return len(self.words)

    def __repr__(self):
        return 'Sentence(%s)' % reprlib.repr(self.text)  
        
- user iter to create a iterator from a function or a callable object 

>>> def d6():
...     return randint(1, 6)
...
>>> d6_iter = iter(d6, 1)
>>> d6_iter
<callable_iterator object at 0x10a245270>
>>> for roll in d6_iter:
...     print(roll)
...
4
3
6
3

- iter from iterable 

>>> s = 'ABC'
>>> it = iter(s)  
>>> while True:
...     try:
...         print(next(it))  
...     except StopIteration:  
...         del it  
...         break  
...
A
B
C

- python standard interface for an iterator has two methods 

__next__ 

__iter__ 


- lazy generator 

The re.finditer function is a lazy version of re.findall. Instead of a list, re.finditer returns a generator yielding re.MatchObject instances on demand. 

- an arithmetic progression generator 

The itertools module in Python 3.10 has 20 generator functions that can be combined in a variety of interesting ways

```
>>> import itertools
>>> gen = itertools.count(1, .5)
>>> next(gen)
```

- yield and yield from statement 

```
def tree(cls):
    yield cls.__name__, 0
    yield from sub_tree(cls, 1)


def sub_tree(cls, level):
    for sub_cls in cls.__subclasses__():
        yield sub_cls.__name__, level
        yield from sub_tree(sub_cls, level+1)


def display(cls):
    for cls_name, level in tree(cls):
        indent = ' ' * 4 * level
        print(f'{indent}{cls_name}')


if __name__ == '__main__':
    display(BaseException)
```

- generic iterable types 

```
from collections.abc import Iterable

FromTo = tuple[str, str]  

def zip_replace(text: str, changes: Iterable[FromTo]) -> str:  
    for from_, to in changes:
        text = text.replace(from_, to)
    return text
```

Generator[YieldType, SendType, ReturnType]

- return a value from a coroutine 

```
from collections.abc import Generator
from typing import Union, NamedTuple

class Result(NamedTuple):  
    count: int  # type: ignore  
    average: float

class Sentinel:  
    def __repr__(self):
        return f'<Sentinel>'

STOP = Sentinel()  

SendType = Union[float, Sentinel]  
```










# Classic coroutines 



# Concurrency models in python 



# Concurrency with futures 



# Asynchronous programming 


# Dynamic attribute and properties 

# Class meta programming 










    
    